import streamlit as st
import pandas as pd
from openai import OpenAI
import requests
import base64
from datetime import datetime
import hashlib
import re

# 1. äº‘ç«¯åŒæ­¥æ ¸å¿ƒå¼•æ“
GH_TOKEN = st.secrets.get("GH_TOKEN")
GH_REPO = st.secrets.get("GH_REPO")

def get_user_id(api_key):
    return hashlib.md5(api_key.encode()).hexdigest()[:8]

def sync_data(uid, df_to_save=None):
    """è‡ªåŠ¨æŒ‰è€å¸ˆ UID åœ¨äº‘ç«¯å­˜å–ä¸“å±æ–‡ä»¶"""
    filename = f"material_lib_{uid}.csv"
    url = f"https://api.github.com/repos/{GH_REPO}/contents/{filename}"
    headers = {"Authorization": f"token {GH_TOKEN}", "Accept": "application/vnd.github.v3+json"}
    
    if df_to_save is None: 
        r = requests.get(url, headers=headers)
        if r.status_code == 200:
            res = r.json()
            content = base64.b64decode(res['content']).decode('utf-8-sig')
            from io import StringIO
            return pd.read_csv(StringIO(content)), res['sha']
        return pd.DataFrame(columns=["æ—¥æœŸ", "æ ‡é¢˜", "æ¶‰åŠæ•™æ", "è€ƒç‚¹è®¾é—®", "ç´ æåŸæ–‡"]), None
    else: 
        r_get = requests.get(url, headers=headers)
        sha = r_get.json().get('sha') if r_get.status_code == 200 else None
        content_b64 = base64.b64encode(df_to_save.to_csv(index=False, encoding='utf-8-sig').encode('utf-8')).decode('utf-8')
        data = {"message": f"æ•™ç ”å‘˜ {uid} è‡ªåŠ¨åŒæ­¥", "content": content_b64, "sha": sha}
        requests.put(url, json=data, headers=headers)
        return None, None

def auto_highlight_fix(text):
    """è§å…‰ç¬”æ¸²æŸ“é€»è¾‘ï¼šå°†åŠ ç²—è½¬ä¸ºé«˜äº®"""
    return re.sub(r'\*\*(.*?)\*\*', r'<mark>\1</mark>', text)

# 2. é¡µé¢ç¾åŒ–ä¸ç™»å½•
st.set_page_config(page_title="æ€æ”¿åå¸ˆÂ·ä¸“å±äº‘æ™ºåº“", layout="wide")
st.markdown("""<style>
    mark { background-color: #ffff00 !important; color: #000 !important; padding: 0 3px; border-radius: 3px; font-weight: bold; }
    .important-red { color: #e11d48 !important; font-weight: bold; }
    .book-tag { background: #fee2e2; color: #b91c1c; padding: 2px 8px; border-radius: 4px; font-size: 12px; font-weight: bold; display: block; margin-bottom: 5px; text-align: center; border: 1px solid #fecaca; }
    .stExpander { border: 1px solid #e2e8f0 !important; border-radius: 12px !important; background: white !important; }
    </style>""", unsafe_allow_html=True)

if 'api_key' not in st.session_state: st.session_state['api_key'] = None

if not st.session_state['api_key']:
    st.title("ğŸ›ï¸ æ€æ”¿åå¸ˆä¸“å±äº‘ç«¯æ™ºåº“")
    st.info("ğŸ’¡ å·²å¼€å¯ã€ä¸€äººä¸€åº“ã€‘æ°¸ä¹…åŒæ­¥æ¨¡å¼ã€‚è¯·è¾“å…¥ API Key ç™»å½•ã€‚")
    key = st.text_input("API Key", type="password")
    if st.button("ğŸš€ å¼€å¯æ•™ç ”ç©ºé—´"):
        if len(key) > 10:
            st.session_state['api_key'] = key
            st.session_state['uid'] = get_user_id(key)
            st.rerun()
else:
    uid = st.session_state['uid']
    df_cloud, current_sha = sync_data(uid)

    with st.sidebar:
        st.header(f"ğŸ‘¤ è€å¸ˆ ID: {uid}")
        st.success("â˜ï¸ ä¸“å±åŒæ­¥ï¼šå·²è¿æ¥")
        if st.button("ğŸšª é€€å‡ºç™»å½•"):
            st.session_state['api_key'] = None
            st.rerun()
        st.divider()
        csv_file = df_cloud.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ“¥ å¯¼å‡ºå…¨åº“å¤‡ä»½", data=csv_file, file_name=f"æ™ºåº“å¤‡ä»½_{uid}.csv", use_container_width=True)

    tab1, tab2 = st.tabs(["âœ¨ ç´ ææ™ºèƒ½åŠ å·¥", "ğŸ“‚ ç»“æ„åŒ–çœ‹æ¿"])

    with tab1:
        l, r = st.columns([1.2, 1])
        with l:
            with st.container(border=True):
                m_title = st.text_input("ç´ ææ ‡é¢˜")
                m_raw = st.text_area("ç´ æåŸæ–‡", height=150)
                m_books = st.multiselect("æ¶‰åŠæ•™æ", options=["å¿…ä¿®1","å¿…ä¿®2","å¿…ä¿®3","å¿…ä¿®4","é€‰ä¿®1","é€‰ä¿®2","é€‰ä¿®3"])
                if st.button("ğŸ§  è·¨æ•™ææ·±åº¦è”åŠ¨åˆ†æ", use_container_width=True):
                    client = OpenAI(api_key=st.session_state['api_key'], base_url="https://api.deepseek.com")
                    prompt = f"""åˆ†æã€Š{m_title}ã€‹åœ¨ã€Š{', '.join(m_books)}ã€‹ä¸­ï¼š
                    1. ã€åˆ†å†Œè§£æã€‘ï¼šå„ä¹¦å¯¹åº”è€ƒç‚¹ã€‚
                    2. ã€è·¨å†Œè”åŠ¨ã€‘ï¼šä¸åŒæ¨¡å—é—´çš„é€»è¾‘è”ç³»ã€‚
                    è§„èŒƒï¼šæ ¸å¿ƒè¯åŠ  <mark>ï¼Œé‡‘å¥ç”¨ <span class='important-red'>ã€‚ä¸¥ç¦åŠ ç²—ã€‚
                    ç´ æï¼š{m_raw}"""
                    resp = client.chat.completions.create(model="deepseek-chat", messages=[{"role":"user","content":prompt}])
                    st.session_state['buffer'] = auto_highlight_fix(resp.choices[0].message.content)

        if 'buffer' in st.session_state:
            final_res = st.text_area("ç²¾ä¿®è§£æå†…å®¹", value=st.session_state['buffer'], height=350)
            if st.button("ğŸ’¾ å½’æ¡£å¹¶æ°¸ä¹…ä¿å­˜", use_container_width=True):
                new_row = {"æ—¥æœŸ": datetime.now().strftime("%Y-%m-%d"), "æ ‡é¢˜": m_title, "æ¶‰åŠæ•™æ": " | ".join(m_books), "è€ƒç‚¹è®¾é—®": final_res, "ç´ æåŸæ–‡": m_raw}
                df_cloud = pd.concat([df_cloud, pd.DataFrame([new_row])], ignore_index=True)
                sync_data(uid, df_cloud) # è‡ªåŠ¨åŒæ­¥
                st.toast("âœ… æ•°æ®å·²æ°¸ä¹…ä¿å­˜åˆ°äº‘ç«¯ï¼")
                del st.session_state['buffer']
                st.rerun()

    with tab2:
        if not df_cloud.empty:
            for i, row in df_cloud.iloc[::-1].iterrows():
                # æ ‡é¢˜åœ¨å‰ï¼Œæ•™æåœ¨å
                with st.expander(f"ğŸ“Œ {row['æ ‡é¢˜']} | {row['æ¶‰åŠæ•™æ']}"):
                    col_l, col_r = st.columns([1, 2.5])
                    with col_l:
                        for b in str(row['æ¶‰åŠæ•™æ']).split(" | "):
                            st.markdown(f"<span class='book-tag'>{b}</span>", unsafe_allow_html=True)
                    with col_r:
                        st.markdown(row['è€ƒç‚¹è®¾é—®'], unsafe_allow_html=True)
                    if st.button(f"ğŸ—‘ï¸ åˆ é™¤è®°å½•", key=f"del_{i}"):
                        df_cloud = df_cloud.drop(i)
                        sync_data(uid, df_cloud)
                        st.rerun()
