import streamlit as st
import pandas as pd
from openai import OpenAI
import os
from datetime import datetime
import hashlib

# 1. é¡µé¢é…ç½®ä¸è§†è§‰ä¼˜åŒ–
st.set_page_config(page_title="æ€æ”¿åå¸ˆæ™ºèƒ½ç´ æåº“", layout="wide", page_icon="ğŸ›ï¸")

st.markdown("""
    <style>
    .stApp { background-color: #f8fafc; }
    /* å¡ç‰‡æ ·å¼ */
    .material-card { 
        background: white; 
        padding: 20px; 
        border-radius: 12px; 
        border-top: 5px solid #b91c1c; 
        box-shadow: 0 4px 6px rgba(0,0,0,0.05); 
        margin-bottom: 20px; 
    }
    /* ä¾§è¾¹æ åŠå…¶ä»–UIå¾®è°ƒ */
    .stDataFrame { border: 1px solid #e2e8f0; border-radius: 8px; }
    .editor-container { background-color: #fffbeb; padding: 20px; border-radius: 12px; border: 1px solid #fcd34d; margin-top: 10px; }
    </style>
    """, unsafe_allow_html=True)

# 2. å·¥å…·å‡½æ•°
def get_user_id(api_key):
    """æ ¹æ®API Keyç”Ÿæˆå”¯ä¸€ç”¨æˆ·IDï¼Œç¡®ä¿æ•°æ®éš”ç¦»"""
    return hashlib.md5(api_key.encode()).hexdigest()[:8]

def get_available_books():
    """è·å–å¹¶å‡€åŒ–æ•™æåç§°ï¼Œè§£å†³æ˜¾ç¤ºä¸å…¨é—®é¢˜"""
    data_path = "data"
    if not os.path.exists(data_path):
        return ["è¯·åˆ›å»ºdataæ–‡ä»¶å¤¹"]
    # å…¼å®¹ .pdf å’Œ .PDFï¼Œå¹¶æ’åº
    files = [f for f in os.listdir(data_path) if f.lower().endswith('.pdf')]
    files.sort()
    # å‡€åŒ–åç§°æ˜¾ç¤ºï¼šå»æ‰åç¼€ï¼Œå»æ‰å¸¸è§å†—ä½™è¯
    cleaned_names = [f.replace('.pdf', '').replace('.PDF', '').replace('é«˜ä¸­æ”¿æ²»', '').strip() for f in files]
    return cleaned_names if cleaned_names else ["æœªæ£€æµ‹åˆ°æ•™æ"]

# 3. ç™»å½•æƒé™æ£€æŸ¥
if 'api_key' not in st.session_state:
    st.session_state['api_key'] = None

if not st.session_state['api_key']:
    st.markdown("<br><br>", unsafe_allow_html=True)
    col_l, col_m, col_r = st.columns([1, 2, 1])
    with col_m:
        st.title("ğŸ›ï¸ æ€æ”¿åå¸ˆä¸“å±ç´ æç©ºé—´")
        st.info("è¯·è¾“å…¥æ‚¨çš„ API Key å¼€å¯äº‘ç«¯æ•™ç ”åº“ã€‚ç³»ç»Ÿå°†æ ¹æ® Key è‡ªåŠ¨éš”ç¦»æ‚¨çš„ç§äººæ•°æ®ã€‚")
        input_key = st.text_input("DeepSeek API Key", type="password")
        if st.button("ğŸš€ è¿›å…¥å·¥ä½œå®¤", use_container_width=True):
            if len(input_key) > 10:
                st.session_state['api_key'] = input_key
                st.session_state['user_id'] = get_user_id(input_key)
                st.rerun()
            else:
                st.error("è¯·è¾“å…¥æœ‰æ•ˆçš„ API Key")
else:
    user_id = st.session_state['user_id']
    user_db = f"material_lib_{user_id}.csv"
    
    # --- ä¾§è¾¹æ ï¼šç®¡ç†ä¸å¯¼å‡º ---
    with st.sidebar:
        st.header(f"ğŸ‘¤ è€å¸ˆ ID: {user_id}")
        if st.button("ğŸšª é€€å‡ºå½“å‰å·¥ä½œå®¤"):
            st.session_state['api_key'] = None
            st.rerun()
        st.divider()
        st.subheader("ğŸ“¥ ç¦»çº¿å¤‡ä»½")
        if os.path.exists(user_db):
            df_exp = pd.read_csv(user_db)
            csv_data = df_exp.to_csv(index=False).encode('utf-8-sig')
            st.download_button("ä¸‹è½½å…¨éƒ¨ç´ æ (Excel/CSV)", data=csv_data, file_name=f"ç´ æå¯¼å‡º_{user_id}.csv", use_container_width=True)
        st.caption("æç¤ºï¼šè‹¥ä¸Šä¼ äº†æ–°æ•™ææ²¡çœ‹åˆ°ï¼Œè¯·å°è¯•åˆ·æ–°é¡µé¢æˆ–ç‚¹å‡»å³ä¸Šè§’ä¸‰ç‚¹-Clear cacheã€‚")

    # --- ä¸»åŠŸèƒ½åŒºï¼šTab åˆ‡æ¢ ---
    tab1, tab2 = st.tabs(["âœ¨ æ™ºèƒ½åŠ å·¥å…¥åº“", "ğŸ“‚ å…¨æ™¯æ•™ç ”çœ‹æ¿"])

    # TAB 1: å½•å…¥åŠ å·¥
    with tab1:
        left_c, right_c = st.columns([1.2, 1])
        with left_c:
            st.subheader("âœï¸ ç´ æè·¨æ•™æåŠ å·¥")
            with st.container(border=True):
                m_title = st.text_input("1. ç´ ææ ‡é¢˜", placeholder="å¦‚ï¼šâ€˜æ–°è´¨ç”Ÿäº§åŠ›â€™å¸¦åŠ¨äº§ä¸šå‡çº§")
                m_raw = st.text_area("2. ç´ æåŸæ–‡å†…å®¹", height=150, placeholder="ç²˜è´´æ—¶æ”¿æŠ¥é“æˆ–æ¡ˆä¾‹åŸæ–‡...")
                
                # è·å–æ•™æåˆ—è¡¨
                book_options = get_available_books()
                m_books = st.multiselect("3. å…³è”æ•™æï¼ˆå¯å¤šé€‰ï¼Œå®ç°é€»è¾‘è·¨è¶Šï¼‰", options=book_options)
                
                if st.button("ğŸ§  AI è·¨æ•™ææ·±åº¦åˆ†æ", use_container_width=True):
                    if not m_title or not m_raw or not m_books:
                        st.warning("è¯·å®Œæ•´å¡«å†™æ ‡é¢˜ã€å†…å®¹å¹¶é€‰æ‹©è‡³å°‘ä¸€æœ¬æ•™æ")
                    else:
                        client = OpenAI(api_key=st.session_state['api_key'], base_url="https://api.deepseek.com")
                        with st.spinner("AI æ­£åœ¨è”åŠ¨æ•™æè§£æçŸ¥è¯†ç‚¹..."):
                            prompt = f"""ä½ æ˜¯ä¸€ä½é«˜ä¸­æ”¿æ²»ç‰¹çº§æ•™å¸ˆã€‚è¯·åˆ†æç´ æã€Š{m_title}ã€‹åœ¨ã€Š{'ã€'.join(m_books)}ã€‹ç­‰æ•™æä¸­çš„æ ¸å¿ƒè€ƒç‚¹ã€‚
                            è¦æ±‚ï¼š
                            1. ã€è·¨æ•™æå®šä½ã€‘ï¼šåˆ†æ•™æåˆ—å‡ºçŸ¥è¯†ç‚¹ï¼ˆå¦‚ï¼šã€å¿…ä¿®2ã€‘... ã€å¿…ä¿®4ã€‘...ï¼‰ã€‚
                            2. ã€æ•™å­¦è®¾é—®ã€‘ï¼šç»™å‡º1-2ä¸ªé«˜è´¨é‡è¯¾å ‚è®¾é—®ã€‚
                            ç´ æå†…å®¹ï¼š{m_raw}"""
                            try:
                                resp = client.chat.completions.create(model="deepseek-chat", messages=[{"role":"user","content":prompt}])
                                st.session_state['analysis_buffer'] = resp.choices[0].message.content
                            except Exception as e:
                                st.error(f"åˆ†æè¯·æ±‚å¤±è´¥ï¼Œè¯·æ£€æŸ¥Keyæˆ–ç½‘ç»œï¼š{e}")

            # è€å¸ˆç²¾ä¿®åŒº
            if 'analysis_buffer' in st.session_state:
                st.markdown('<div class="editor-container">', unsafe_allow_html=True)
                st.markdown("âœï¸ **è€å¸ˆç²¾ä¿®åŒº**ï¼ˆæ‚¨å¯ä»¥æ ¹æ®å®é™…æ•™å­¦è°ƒæ•´ AI çš„è¡¨è¿°ï¼‰")
                final_analysis = st.text_area("è€ƒç‚¹åˆ†æä¸è®¾é—®å»ºè®®", value=st.session_state['analysis_buffer'], height=300)
                
                if st.button("ğŸ’¾ ç¡®è®¤å¹¶å­˜å…¥æ¡£æ¡ˆåº“", use_container_width=True):
                    new_entry = {
                        "æ—¥æœŸ": datetime.now().strftime("%Y-%m-%d"),
                        "æ ‡é¢˜": m_title,
                        "å…³è”æ•™æ": " | ".join(m_books),
                        "æ ¸å¿ƒçŸ¥è¯†ç‚¹": final_analysis,
                        "åŸæ–‡": m_raw
                    }
                    df = pd.read_csv(user_db) if os.path.exists(user_db) else pd.DataFrame(columns=["æ—¥æœŸ","æ ‡é¢˜","å…³è”æ•™æ","æ ¸å¿ƒçŸ¥è¯†ç‚¹","åŸæ–‡"])
                    df = pd.concat([df, pd.DataFrame([new_entry])], ignore_index=True)
                    df.to_csv(user_db, index=False, encoding='utf-8-sig')
                    st.success("âœ… ç´ æå½’æ¡£æˆåŠŸï¼")
                    del st.session_state['analysis_buffer']
                    st.rerun()
                st.markdown('</div>', unsafe_allow_html=True)

        with right_c:
            st.subheader("ğŸ’¡ æ•™ç ”å»ºè®®")
            st.info("æ‚¨å¯ä»¥ä¸€æ¬¡æ€§å‹¾é€‰ã€Šå¿…ä¿®2ã€‹å’Œã€Šå¿…ä¿®4ã€‹ï¼ŒAI ä¼šè‡ªåŠ¨ä¸ºæ‚¨æ„å»ºâ€˜ç»æµç”Ÿæ´»â€™ä¸â€˜å“²å­¦é€»è¾‘â€™çš„è·¨è¯¾æ¡¥æ¢ã€‚")

    # TAB 2: å…¨æ™¯çœ‹æ¿ (è¡¨æ ¼ + å¡ç‰‡)
    with tab2:
        if os.path.exists(user_db):
            full_df = pd.read_csv(user_db).fillna("")
            
            # å­—æ®µåå…¼å®¹æ€§ä¿®å¤ï¼ˆè§£å†³ KeyæŠ¥é”™ï¼‰
            name_map = {'ç²¾ä¿®è§£æ': 'æ ¸å¿ƒçŸ¥è¯†ç‚¹', 'æ ¸å¿ƒè§£æ': 'æ ¸å¿ƒçŸ¥è¯†ç‚¹', 'åˆ†æç»“æœ': 'æ ¸å¿ƒçŸ¥è¯†ç‚¹'}
            for old_name, new_name in name_map.items():
                if old_name in full_df.columns and new_name not in full_df.columns:
                    full_df.rename(columns={old_name: new_name}, inplace=True)

            st.subheader("ğŸ“– ç»“æ„åŒ–ç´ ææ¸…å•è¡¨")
            # æœç´¢è¿‡æ»¤
            search_q = st.text_input("ğŸ” å…¨åº“æœç´¢ï¼ˆæ ‡é¢˜ã€æ•™æã€è€ƒç‚¹å…³é”®è¯ï¼‰")
            if search_q:
                full_df = full_df[full_df.apply(lambda r: r.astype(str).str.contains(search_q).any(), axis=1)]

            # å¼ºåŒ–è¡¨æ ¼ç´¢å¼•è§†å›¾
            view_df = full_df.copy()
            view_df['çŸ¥è¯†é¢„è§ˆ'] = view_df['æ ¸å¿ƒçŸ¥è¯†ç‚¹'].apply(lambda x: str(x).replace('\n', ' ')[:80] + '...')
            
            st.dataframe(
                view_df[["æ—¥æœŸ", "æ ‡é¢˜", "å…³è”æ•™æ", "çŸ¥è¯†é¢„è§ˆ"]],
                use_container_width=True,
                hide_index=True,
                column_config={
                    "æ—¥æœŸ": st.column_config.Column(width="small"),
                    "æ ‡é¢˜": st.column_config.Column("ç´ ææ ‡é¢˜", width="medium"),
                    "å…³è”æ•™æ": st.column_config.Column("å¯¹åº”ä¹¦ç›®", width="medium"),
                    "çŸ¥è¯†é¢„è§ˆ": st.column_config.Column("æ ¸å¿ƒè€ƒç‚¹ä¸€è§ˆ", width="large"),
                }
            )

            st.divider()

            # è¯¦ç»†å¡ç‰‡è§†å›¾
            st.subheader("ğŸ—‚ï¸ è¯¦ç»†æ¡£æ¡ˆå¡ç‰‡")
            for i, row in full_df.iloc[::-1].iterrows():
                with st.container():
                    st.markdown(f"""
                    <div class="material-card">
                        <small style="color:#b91c1c; font-weight:bold;">{row['å…³è”æ•™æ']}</small>
                        <h3 style="margin:5px 0;">{row['æ ‡é¢˜']}</h3>
                        <p style="font-size:12px; color:gray;">å…¥åº“æ—¥æœŸï¼š{row['æ—¥æœŸ']}</p>
                    </div>
                    """, unsafe_allow_html=True)
                    with st.expander("æŸ¥çœ‹å®Œæ•´åˆ†æä¸åŸæ–‡å†…å®¹"):
                        c1, c2 = st.columns([1.5, 1])
                        with c1:
                            st.markdown("**ã€è·¨æ•™ææ•™ç ”åˆ†æã€‘**")
                            st.write(row['æ ¸å¿ƒçŸ¥è¯†ç‚¹'])
                        with c2:
                            st.markdown("**ã€åŸæ–‡å‚è€ƒã€‘**")
                            st.caption(row.get('åŸæ–‡', "æ— åŸæ–‡ä¿¡æ¯"))
                        if st.button(f"ğŸ—‘ï¸ åˆ é™¤è¯¥æ¡ç´ æ", key=f"del_{i}"):
                            full_df.drop(i).to_csv(user_db, index=False, encoding='utf-8-sig')
                            st.rerun()
        else:
            st.info("æ‚¨çš„æ¡£æ¡ˆåº“è¿˜æ˜¯ç©ºçš„ï¼Œå¿«å»åŠ å·¥ç¬¬ä¸€æ¡ç´ æå§ï¼")
