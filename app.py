import streamlit as st
import pandas as pd
from openai import OpenAI
import os
import pdfplumber
from datetime import datetime
import hashlib

st.set_page_config(page_title="æˆ‘çš„æ€æ”¿ç´ æåº“", page_icon="ğŸ—ƒï¸", layout="wide")

# è‡ªå®šä¹‰æ ·å¼ï¼šå¼ºè°ƒâ€œä»“åº“â€çš„æ„Ÿè§‰
st.markdown("""
    <style>
    .stApp { background-color: #f3f4f6; }
    .input-card { background: white; padding: 20px; border-radius: 10px; border: 1px solid #e5e7eb; box-shadow: 0 2px 4px rgba(0,0,0,0.05); }
    .tag { display: inline-block; background: #e0f2fe; color: #0369a1; padding: 2px 8px; border-radius: 4px; font-size: 0.8em; margin-right: 5px; }
    </style>
    """, unsafe_allow_html=True)

# --- æ ¸å¿ƒï¼šç”¨æˆ·éš”ç¦»ä¸è¯»å– ---
def get_user_hash(api_key):
    return hashlib.md5(api_key.encode()).hexdigest()[:8]

@st.cache_data(show_spinner=False)
def load_all_textbooks():
    """è¯»å–æ‰€æœ‰æ•™æï¼Œæ„å»ºä¸€ä¸ªå¤§çš„çŸ¥è¯†èƒŒæ™¯"""
    data_dir = "data"
    combined_text = ""
    if not os.path.exists(data_dir): return ""
    files = [f for f in os.listdir(data_dir) if f.endswith('.pdf')]
    for f in files:
        try:
            with pdfplumber.open(os.path.join(data_dir, f)) as pdf:
                # æ¯æœ¬ä¹¦æå–å‰40é¡µä½œä¸ºç´¢å¼•ä¾æ®
                for page in pdf.pages[:40]:
                    txt = page.extract_text()
                    if txt: combined_text += txt + "\n"
        except: pass
    return combined_text

# --- ç™»å½•é€»è¾‘ ---
if 'api_key' not in st.session_state:
    st.session_state['api_key'] = None

if not st.session_state['api_key']:
    c1, c2, c3 = st.columns([1,2,1])
    with c2:
        st.title("ğŸ—ƒï¸ ä¸ªäººä¸“å±ç´ æåº“")
        st.info("è¾“å…¥æ‚¨çš„ Keyï¼Œç³»ç»Ÿå°†è‡ªåŠ¨åŠ è½½æ‚¨ä¸ªäººçš„ç´ ææ¡£æ¡ˆã€‚")
        k = st.text_input("DeepSeek API Key", type="password")
        if st.button("ğŸ”“ æ‰“å¼€æˆ‘çš„ç´ æåº“", use_container_width=True):
            if len(k) > 5:
                st.session_state['api_key'] = k
                st.session_state['user_id'] = get_user_hash(k)
                st.rerun()
else:
    # --- ç™»å½•åçš„ä¸»ç•Œé¢ ---
    user_id = st.session_state['user_id']
    db_file = f"library_{user_id}.csv" # æ¯ä¸ªäººçš„åº“æ–‡ä»¶åä¸ä¸€æ ·
    
    # é¢„åŠ è½½æ•™æèƒŒæ™¯
    with st.spinner("æ­£åœ¨è¿æ¥äº‘ç«¯æ•™æåº“..."):
        textbook_context = load_all_textbooks()

    # ä¾§è¾¹æ 
    with st.sidebar:
        st.write(f"ğŸ‘¤ ç”¨æˆ·ID: `{user_id}`")
        if st.button("é€€å‡º"):
            st.session_state['api_key'] = None
            st.rerun()
        st.divider()
        st.markdown("### ğŸ“Š åº“å†…ç»Ÿè®¡")
        if os.path.exists(db_file):
            df = pd.read_csv(db_file)
            st.metric("å·²æ”¶å½•ç´ æ", f"{len(df)} æ¡")
        else:
            st.metric("å·²æ”¶å½•ç´ æ", "0 æ¡")

    st.title("ğŸ—ƒï¸ æ™ºèƒ½ç´ æåŠ å·¥å‚")

    # é¡µé¢å¸ƒå±€ï¼šå·¦è¾¹å½•å…¥ï¼Œå³è¾¹æŸ¥çœ‹
    tab1, tab2 = st.tabs(["â• ç´ æå…¥åº“ (AI è‡ªåŠ¨æ‰“æ ‡)", "ğŸ” æ£€ç´¢æˆ‘çš„åº“"])

    with tab1:
        st.markdown('<div class="input-card">', unsafe_allow_html=True)
        col1, col2 = st.columns([3, 1])
        with col1:
            material_title = st.text_input("ç´ ææ ‡é¢˜", placeholder="ä¾‹å¦‚ï¼š2024å¤®è§†æ˜¥æ™šå°å“ã€Š...ã€‹")
        with col2:
            material_type = st.selectbox("ç±»å‹", ["æ—¶æ”¿æ–°é—»", "ç”Ÿæ´»æ¡ˆä¾‹", "åè¨€è­¦å¥", "å…¸æ•…å†å²"])
            
        material_content = st.text_area("ç²˜è´´ç´ æå†…å®¹", height=200, placeholder="åœ¨è¿™é‡Œç²˜è´´åŸæ–‡...")
        
        if st.button("âœ¨ AI æ™ºèƒ½åˆ†æå¹¶å…¥åº“", use_container_width=True):
            if not textbook_context:
                st.error("è¯·å…ˆåœ¨ GitHub data æ–‡ä»¶å¤¹ä¸Šä¼ æ•™æï¼")
            elif not material_content:
                st.warning("è¯·å¡«å†™å†…å®¹")
            else:
                client = OpenAI(api_key=st.session_state['api_key'], base_url="https://api.deepseek.com")
                with st.spinner("AI æ­£åœ¨ç¿»é˜…æ•™æï¼Œä¸ºæ‚¨åŒ¹é…è€ƒç‚¹..."):
                    # è¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºâ€œæ‰“æ ‡ç­¾â€çš„ Prompt
                    prompt = f"""
                    ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„æ•™ææ¡£æ¡ˆç®¡ç†å‘˜ã€‚
                    å‚è€ƒæ•™æå†…å®¹ï¼š{textbook_context[:20000]}
                    
                    å¾…åˆ†æç´ æï¼š
                    æ ‡é¢˜ï¼š{material_title}
                    å†…å®¹ï¼š{material_content}
                    
                    è¯·åˆ†æè¯¥ç´ æä¸é«˜ä¸­æ”¿æ²»æ•™æçš„è”ç³»ï¼Œå¹¶ä¸¥æ ¼æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼ˆä¸è¦åºŸè¯ï¼‰ï¼š
                    
                    é€‚ç”¨æ•™æï¼š(ä¾‹å¦‚ï¼šå¿…ä¿®1ã€å¿…ä¿®3)
                    æ ¸å¿ƒè€ƒç‚¹ï¼š(æå–3-5ä¸ªæœ€ç›¸å…³çš„å…³é”®è¯ï¼Œç”¨é¡¿å·éš”å¼€)
                    é€‚ç”¨åˆ†æï¼š(ç”¨ä¸€å¥è¯æ¦‚æ‹¬è¿™ä¸ªç´ æé€‚åˆç”¨æ¥è¯´æ˜ä»€ä¹ˆåŸç†ï¼Œ50å­—ä»¥å†…)
                    """
                    
                    try:
                        resp = client.chat.completions.create(
                            model="deepseek-chat",
                            messages=[{"role": "user", "content": prompt}]
                        )
                        ai_result = resp.choices[0].message.content
                        
                        # è§£æ AI è¿”å›çš„ç»“æœ (è¿™é‡Œåšä¸€ä¸ªç®€å•çš„åˆ†å‰²å¤„ç†ï¼Œå®é™…å¯ä»¥æ›´å¤æ‚)
                        # ä¸ºäº†æ¼”ç¤ºç¨³å®šï¼Œæˆ‘ä»¬ç›´æ¥æŠŠ AI çš„æ•´æ®µå›å¤å­˜è¿›å»ï¼Œæˆ–è€…è®© AI è¿”å› JSON
                        # è¿™é‡Œç®€å•å¤„ç†ï¼Œç›´æ¥å­˜
                        
                        new_data = {
                            "å½•å…¥æ—¶é—´": datetime.now().strftime("%Y-%m-%d"),
                            "æ ‡é¢˜": material_title,
                            "ç±»å‹": material_type,
                            "åŸæ–‡æ‘˜è¦": material_content[:50]+"...", # åªå­˜å‰50å­—é¢„è§ˆ
                            "AIæ™ºèƒ½æ ‡ç­¾": ai_result, # å­˜å…¥ AI åˆ†æçš„å…¨éƒ¨å†…å®¹
                            "å®Œæ•´å†…å®¹": material_content
                        }
                        
                        # å­˜å…¥ CSV
                        df = pd.read_csv(db_file) if os.path.exists(db_file) else pd.DataFrame(columns=["å½•å…¥æ—¶é—´","æ ‡é¢˜","ç±»å‹","åŸæ–‡æ‘˜è¦","AIæ™ºèƒ½æ ‡ç­¾","å®Œæ•´å†…å®¹"])
                        df = pd.concat([df, pd.DataFrame([new_data])], ignore_index=True)
                        df.to_csv(db_file, index=False, encoding='utf-8-sig')
                        
                        st.success("âœ… å·²æˆåŠŸå…¥åº“ï¼")
                        st.markdown(f"**AI åˆ†æç»“æœï¼š**\n{ai_result}")
                        
                    except Exception as e:
                        st.error(f"å¤„ç†å¤±è´¥: {e}")
        st.markdown('</div>', unsafe_allow_html=True)

    with tab2:
        if os.path.exists(db_file):
            df = pd.read_csv(db_file)
            
            # æœç´¢æ¡†
            search = st.text_input("ğŸ” æœç´¢åº“å†…ç´ æï¼ˆæ”¯æŒæ ‡é¢˜ã€è€ƒç‚¹æœç´¢ï¼‰")
            if search:
                # æ¨¡ç³Šæœç´¢
                df = df[df.apply(lambda row: row.astype(str).str.contains(search).any(), axis=1)]
            
            # è¡¨æ ¼å±•ç¤º
            st.dataframe(
                df[["å½•å…¥æ—¶é—´", "æ ‡é¢˜", "ç±»å‹", "AIæ™ºèƒ½æ ‡ç­¾"]], 
                use_container_width=True,
                height=500
            )
            
            # ä¸‹è½½å¤‡ä»½
            with open(db_file, "rb") as f:
                st.download_button("ğŸ“¥ å¯¼å‡ºæˆ‘çš„ç´ æåº“ (Excel/CSV)", f, file_name=f"my_materials_{user_id}.csv")
        else:
            st.info("æ‚¨çš„åº“è¿˜æ˜¯ç©ºçš„ï¼Œå¿«å»å½•å…¥ç¬¬ä¸€æ¡ç´ æå§ï¼")

