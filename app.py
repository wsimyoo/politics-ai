import streamlit as st
import pandas as pd
from openai import OpenAI
import os
from datetime import datetime
import hashlib

# 1. é¡µé¢é…ç½®ä¸é«˜çº§æ ·å¼
st.set_page_config(page_title="æ€æ”¿åå¸ˆæ™ºèƒ½ç´ æåº“", layout="wide", page_icon="ğŸ›ï¸")

st.markdown("""
    <style>
    .stApp { background-color: #f8fafc; }
    /* è§å…‰ç¬”é«˜äº®æ ·å¼ */
    mark { background-color: #fef08a; padding: 0 4px; border-radius: 4px; font-weight: bold; color: #000; }
    .important-red { color: #dc2626; font-weight: bold; }
    /* æŠ˜å æ¡†ç¾åŒ– */
    .stExpander { border: 1px solid #e2e8f0 !important; background-color: white !important; border-radius: 12px !important; margin-bottom: 10px !important; }
    /* æ•™æè‰²å—æ ‡ç­¾ */
    .book-tag { background: #fee2e2; color: #b91c1c; padding: 2px 8px; border-radius: 4px; font-size: 12px; font-weight: bold; display: block; margin-bottom: 5px; text-align: center; }
    </style>
    """, unsafe_allow_html=True)

# 2. æ ¸å¿ƒé²æ£’æ€§é€»è¾‘ï¼šè§£å†³ KeyError å’Œæ•™ææ˜¾ç¤ºé—®é¢˜
def get_user_id(api_key):
    return hashlib.md5(api_key.encode()).hexdigest()[:8]

def get_available_books():
    """å¼ºåˆ¶æ‰«æ data ç›®å½•ï¼Œè§£å†³æ˜¾ç¤ºä¸å…¨"""
    d_path = "data"
    if not os.path.exists(d_path): os.makedirs(d_path)
    # åªè¦æ˜¯æ–‡ä»¶å°±å±•ç¤ºï¼ˆä¸é™åˆ¶åç¼€ï¼‰ï¼Œé˜²æ­¢è¯¯åˆ åç¼€å¯¼è‡´è¯†åˆ«å¤±è´¥
    files = [f for f in os.listdir(d_path) if not f.startswith('.')]
    files.sort()
    return [f.replace('.pdf', '').replace('.PDF', '').replace('é«˜ä¸­æ”¿æ²»', '').strip() for f in files]

def load_and_fix_db(file_path):
    """ã€é»‘ç§‘æŠ€ã€‘è‡ªåŠ¨å¯¹é½åˆ—åï¼Œå½»åº•ç»ˆç»“ KeyError"""
    standard_cols = ["æ—¥æœŸ", "æ ‡é¢˜", "æ¶‰åŠæ•™æ", "è€ƒç‚¹è®¾é—®", "ç´ æåŸæ–‡"]
    if not os.path.exists(file_path):
        return pd.DataFrame(columns=standard_cols)
    
    try:
        df = pd.read_csv(file_path)
        # å…¼å®¹æ€§æ˜ å°„ï¼šå°†æ—§ç‰ˆæœ¬çš„å„ç§åˆ—åå¼ºåˆ¶å¯¹é½åˆ°æ ‡å‡†ç‰ˆ
        rename_map = {
            'ç²¾ä¿®è§£æ': 'è€ƒç‚¹è®¾é—®', 'æ ¸å¿ƒçŸ¥è¯†ç‚¹': 'è€ƒç‚¹è®¾é—®', 'æ ¸å¿ƒè§£æ': 'è€ƒç‚¹è®¾é—®', 'åˆ†æç»“æœ': 'è€ƒç‚¹è®¾é—®',
            'å…³è”æ•™æ': 'æ¶‰åŠæ•™æ', 'æ•™æ': 'æ¶‰åŠæ•™æ', 'æ¶‰åŠæ•™æ ': 'æ¶‰åŠæ•™æ',
            'åŸæ–‡': 'ç´ æåŸæ–‡', 'ç´ æåŸæ–‡å†…å®¹': 'ç´ æåŸæ–‡', 'åŸæ–‡å†…å®¹': 'ç´ æåŸæ–‡'
        }
        df.rename(columns=rename_map, inplace=True)
        
        # è¡¥é½ç¼ºå¤±åˆ—
        for col in standard_cols:
            if col not in df.columns:
                df[col] = "æœªè®°å½•"
        
        return df[standard_cols]
    except Exception:
        return pd.DataFrame(columns=standard_cols)

# 3. ç™»å½•æƒé™
if 'api_key' not in st.session_state: st.session_state['api_key'] = None

if not st.session_state['api_key']:
    st.markdown("<br><br>", unsafe_allow_html=True)
    col_l, col_m, col_r = st.columns([1, 2, 1])
    with col_m:
        st.title("ğŸ›ï¸ æ€æ”¿åå¸ˆå·¥ä½œå®¤")
        st.info("ç³»ç»Ÿå°†æ ¹æ® API Key è‡ªåŠ¨éš”ç¦»ä¸åŒè€å¸ˆçš„äº‘ç«¯æ•°æ®åº“ã€‚")
        input_key = st.text_input("è¯·è¾“å…¥æ‚¨çš„ DeepSeek API Key", type="password")
        if st.button("ğŸš€ å¼€å¯æ•™ç ”å®¤", use_container_width=True):
            if len(input_key) > 10:
                st.session_state['api_key'] = input_key
                st.session_state['uid'] = get_user_id(input_key)
                st.rerun()
else:
    uid = st.session_state['uid']
    db_file = f"material_lib_{uid}.csv"
    book_options = get_available_books()

    # --- ä¾§è¾¹æ  ---
    with st.sidebar:
        st.header(f"ğŸ‘¤ è€å¸ˆ ID: {uid}")
        if st.button("ğŸšª é€€å‡ºç™»å½•"):
            st.session_state['api_key'] = None
            st.rerun()
        st.divider()
        st.subheader("ğŸ“¥ æ•°æ®å¤‡ä»½")
        df_tmp = load_and_fix_db(db_file)
        if not df_tmp.empty:
            csv = df_tmp.to_csv(index=False).encode('utf-8-sig')
            st.download_button("ä¸‹è½½å…¨éƒ¨æ•™ç ”æˆæœ", data=csv, file_name=f"æ€æ”¿æ™ºåº“_{datetime.now().strftime('%Y%m%d')}.csv", use_container_width=True)

    tab1, tab2 = st.tabs(["âœ¨ æ™ºèƒ½å½•å…¥åŠ å·¥", "ğŸ“‚ ç»“æ„åŒ–å…¨æ™¯çœ‹æ¿"])

    # TAB 1: å½•å…¥ä¸ AI è§å…‰ç¬”é«˜äº®
    with tab1:
        left_c, right_c = st.columns([1.2, 1])
        with left_c:
            with st.container(border=True):
                m_title = st.text_input("1. ç´ ææ ‡é¢˜")
                m_raw = st.text_area("2. ç´ æåŸæ–‡", height=150)
                m_books = st.multiselect("3. å…³è”æ•™æ", options=book_options)
                
                if st.button("ğŸ§  AI è·¨æ•™æé«˜äº®åˆ†æ", use_container_width=True):
                    if not m_title or not m_raw or not m_books:
                        st.warning("è¯·è¡¥å…¨ä¿¡æ¯åå†åˆ†æ")
                    else:
                        client = OpenAI(api_key=st.session_state['api_key'], base_url="https://api.deepseek.com")
                        with st.spinner("æ­£åœ¨æ¶‚æŠ¹è§å…‰ç¬”é‡ç‚¹..."):
                            prompt = f"""ä½ æ˜¯ä¸€ä½æ€æ”¿åå¸ˆã€‚è¯·åˆ†æç´ æã€Š{m_title}ã€‹åœ¨ã€Š{'ã€'.join(m_books)}ã€‹ä¸­çš„æ ¸å¿ƒè€ƒç‚¹ã€‚
                            è¦æ±‚ï¼š
                            1. å°†æœ€æ ¸å¿ƒçš„ã€è€ƒç‚¹è¯æ±‡ã€‘ç”¨ <mark>æ ‡ç­¾åŒ…å›´ </mark>ï¼ˆè§å…‰ç¬”æ•ˆæœï¼‰ã€‚
                            2. å°†ã€å…³é”®ç»“è®ºã€‘ç”¨ <span class='important-red'>çº¢è‰²æ ·å¼åŒ…å›´ </span>ã€‚
                            3. ç»™å‡º1-2ä¸ªè¯¾å ‚è®¾é—®ã€‚æ–‡å­—ç²¾ç‚¼ï¼Œé€»è¾‘æ¸…æ™°ã€‚
                            ç´ æå†…å®¹ï¼š{m_raw}"""
                            resp = client.chat.completions.create(model="deepseek-chat", messages=[{"role":"user","content":prompt}])
                            st.session_state['buffer'] = resp.choices[0].message.content

            if 'buffer' in st.session_state:
                st.markdown("âœï¸ **è€å¸ˆç²¾ä¿®ä¸é¢„è§ˆ**ï¼ˆæ ‡è®°è¯­æ³•ï¼š`<mark>é«˜äº®</mark>`ï¼‰")
                final_res = st.text_area("è€ƒç‚¹è§£æ", value=st.session_state['buffer'], height=300)
                if st.button("ğŸ’¾ å½’æ¡£è‡³äº‘ç«¯åº“", use_container_width=True):
                    df = load_and_fix_db(db_file)
                    new_row = {"æ—¥æœŸ": datetime.now().strftime("%Y-%m-%d"), "æ ‡é¢˜": m_title, "æ¶‰åŠæ•™æ": " | ".join(m_books), "è€ƒç‚¹è®¾é—®": final_res, "ç´ æåŸæ–‡": m_raw}
                    pd.concat([df, pd.DataFrame([new_row])], ignore_index=True).to_csv(db_file, index=False, encoding='utf-8-sig')
                    st.success("å½’æ¡£æˆåŠŸï¼å·²å­˜å…¥çœ‹æ¿ã€‚")
                    del st.session_state['buffer']
                    st.rerun()

    # TAB 2: åˆ†åˆ—å‘ˆç°çœ‹æ¿
    with tab2:
        df = load_and_fix_db(db_file)
        if not df.empty:
            st.subheader("ğŸ“ æç®€æ•™ç ”æ¸…å•")
            # è¿™é‡Œçš„è¡¨æ ¼ç»å¯¹ä¸ä¼šæŠ¥ KeyError
            st.dataframe(df[["æ—¥æœŸ", "æ ‡é¢˜", "æ¶‰åŠæ•™æ"]], use_container_width=True, hide_index=True)
            
            st.divider()
            st.subheader("ğŸ“– åˆ†åˆ—è¯¦æƒ…é¢„è§ˆ (æ”¯æŒè§å…‰ç¬”æ•ˆæœ)")
            
            # å¢åŠ æœç´¢åŠŸèƒ½
            q = st.text_input("ğŸ” æœç´¢åº“å†…ç´ æ...")
            show_df = df[df.apply(lambda r: r.astype(str).str.contains(q).any(), axis=1)] if q else df
            
            for i, row in show_df.iloc[::-1].iterrows():
                # ä½¿ç”¨ expander å®ç°æ‚¨çš„æŠ˜å æƒ³æ³•
                with st.expander(f"ğŸ“Œ {row['æ¶‰åŠæ•™æ']} | {row['æ ‡é¢˜']}"):
                    col_book, col_detail = st.columns([1, 2.5])
                    with col_book:
                        st.markdown("**ğŸ“š æ¶‰åŠæ•™æ**")
                        for b in str(row['æ¶‰åŠæ•™æ']).split(" | "):
                            st.markdown(f"<span class='book-tag'>{b}</span>", unsafe_allow_html=True)
                    with col_detail:
                        st.markdown("**ğŸ’¡ æ ¸å¿ƒè€ƒç‚¹ä¸è§£æ**")
                        # æ¸²æŸ“é«˜äº®å’Œé¢œè‰²
                        st.markdown(row['è€ƒç‚¹è®¾é—®'], unsafe_allow_html=True)
                    
                    st.divider()
                    st.caption(f"ç´ æåŸæ–‡å‚è€ƒï¼š{row.get('ç´ æåŸæ–‡', '')}")
                    if st.button(f"ğŸ—‘ï¸ åˆ é™¤æ­¤ç´ æ", key=f"del_{i}"):
                        df.drop(i).to_csv(db_file, index=False, encoding='utf-8-sig')
                        st.rerun()
        else:
            st.info("æš‚æ— ç´ æã€‚")
