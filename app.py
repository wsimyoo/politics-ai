import streamlit as st
import pandas as pd
from github import Github
from openai import OpenAI
import hashlib
import re
import io
from datetime import datetime

# --- 1. æ ·å¼é…ç½® ---
st.set_page_config(page_title="æ€æ”¿åå¸ˆæ™ºèƒ½ç´ æåº“", layout="wide", page_icon="ğŸ›ï¸")

st.markdown("""
    <style>
    .stApp { background-color: #f8fafc; }
    mark { background-color: #ffff00 !important; color: #000 !important; padding: 0 3px; border-radius: 3px; font-weight: bold; }
    .important-red { color: #e11d48 !important; font-weight: bold; }
    .stExpander { border: 1px solid #e2e8f0 !important; border-radius: 12px !important; background: white !important; margin-bottom: 10px !important; }
    .book-tag { 
        background: #fee2e2; color: #b91c1c; padding: 2px 8px; border-radius: 4px; 
        font-size: 12px; font-weight: bold; display: block; margin-bottom: 5px; 
        text-align: center; border: 1px solid #fecaca;
    }
    </style>
    """, unsafe_allow_html=True)

# --- 2. æ ¸å¿ƒå¼•æ“å‡½æ•° ---
def get_github_repo():
    return Github(st.secrets["GH_TOKEN"]).get_repo(st.secrets["GH_REPO"])

def get_available_books():
    try:
        repo = get_github_repo()
        files = repo.get_contents("data")
        books = [f.name.replace('.pdf', '').replace('.PDF', '').strip() for f in files if f.name.endswith(('.pdf', '.PDF'))]
        return sorted(books)
    except:
        return ["å¿…ä¿®1", "å¿…ä¿®2", "å¿…ä¿®3", "å¿…ä¿®4"]

def load_from_cloud(uid):
    file_path = f"material_lib_{uid}.csv"
    standard_cols = ["æ—¥æœŸ", "æ ‡é¢˜", "æ¶‰åŠæ•™æ", "è€ƒç‚¹è®¾é—®", "ç´ æåŸæ–‡"]
    try:
        repo = get_github_repo()
        content = repo.get_contents(file_path)
        df = pd.read_csv(content.download_url)
        rename_map = {'ç´ ææ ‡é¢˜': 'æ ‡é¢˜', 'ç²¾ä¿®è§£æ': 'è€ƒç‚¹è®¾é—®', 'æ ¸å¿ƒè§£æ': 'è€ƒç‚¹è®¾é—®', 'åˆ†ç±»': 'æ¶‰åŠæ•™æ'}
        df.rename(columns=rename_map, inplace=True)
        for col in standard_cols:
            if col not in df.columns: df[col] = "æœªè®°å½•"
        return df[standard_cols], content.sha
    except:
        return pd.DataFrame(columns=standard_cols), None

# --- 3. ç™»å½•æƒé™æ‹¦æˆª (å½»åº•ä¿®å¤ KeyError) ---
if 'uid' not in st.session_state:
    st.session_state['uid'] = None

if not st.session_state['uid']:
    st.markdown("<br><br>", unsafe_allow_html=True)
    col_l, col_m, col_r = st.columns([1, 2, 1])
    with col_m:
        st.title("ğŸ›ï¸ æ€æ”¿åå¸ˆå·¥ä½œå®¤")
        input_key = st.text_input("è¯·è¾“å…¥ DeepSeek API Key ç™»å½•", type="password")
        if st.button("ğŸš€ å¼€å¯å·¥ä½œå®¤", use_container_width=True):
            if len(input_key) > 10:
                st.session_state['api_key'] = input_key
                st.session_state['uid'] = hashlib.md5(input_key.encode()).hexdigest()[:8]
                st.rerun()
            else:
                st.error("è¯·è¾“å…¥æœ‰æ•ˆçš„ API Key")
    # å…³é”®ç‚¹ï¼šå¦‚æœæ²¡æœ‰ç™»å½•ï¼Œç›´æ¥åœæ­¢åé¢æ‰€æœ‰ä»£ç çš„æ‰§è¡Œï¼Œé˜²æ­¢æŠ¥é”™
    st.stop()

# --- 4. åªæœ‰ç™»å½•æˆåŠŸæ‰ä¼šæ‰§è¡Œåˆ°è¿™é‡Œ ---
uid = st.session_state['uid']
db_filename = f"material_lib_{uid}.csv"
book_options = get_available_books()
df_cloud, current_sha = load_from_cloud(uid)

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header(f"ğŸ‘¤ è€å¸ˆ ID: {uid}")
    if st.button("ğŸ”„ å¼ºåˆ¶åŒæ­¥äº‘ç«¯æ•°æ®", use_container_width=True):
        st.rerun()
    st.divider()
    st.subheader("ğŸ“¥ æˆæœå¯¼å‡º")
    if not df_cloud.empty:
        csv_io = io.BytesIO()
        df_cloud.to_csv(csv_io, index=False, encoding='utf-8-sig')
        st.download_button("å¯¼å‡º CSV æ¸…å•", data=csv_io.getvalue(), file_name=f"æ€æ”¿æ™ºåº“_{datetime.now().strftime('%m%d')}.csv", use_container_width=True)
    st.divider()
    if st.button("ğŸšª é€€å‡ºç™»å½•"):
        st.session_state.clear()
        st.rerun()

# --- ä¸»åŠŸèƒ½åŒº ---
tab1, tab2 = st.tabs(["âœ¨ æ™ºèƒ½åŠ å·¥å½•å…¥", "ğŸ“‚ ç»“æ„åŒ–å…¨æ™¯çœ‹æ¿"])

with tab1:
    l_col, r_col = st.columns([1.2, 1])
    with l_col:
        with st.container(border=True):
            m_title = st.text_input("1. ç´ ææ ‡é¢˜")
            m_raw = st.text_area("2. ç´ æåŸæ–‡", height=200)
            m_books = st.multiselect("3. å…³è”æ•™æ (æ”¯æŒè”åŠ¨)", options=book_options)
            
            if st.button("ğŸ§  å¼€å¯å¤šç»´æ·±åº¦é«˜äº®åˆ†æ", use_container_width=True):
                if m_title and m_books and m_raw:
                    client = OpenAI(api_key=st.session_state['api_key'], base_url="https://api.deepseek.com")
                    with st.spinner("è”åŠ¨æ•™ç ”åˆ†æä¸­..."):
                        prompt = f"ä½ æ˜¯æ€æ”¿åå¸ˆã€‚é’ˆå¯¹ã€Š{m_title}ã€‹ç»“åˆæ•™æ {m_books} åˆ†æã€‚è¾“å‡ºåˆ†å†Œè§£æã€è”åŠ¨åˆ†æã€æ•™å­¦è®¾é—®ã€‚ä¸¥ç¦åŠ ç²—ã€‚æ ¸å¿ƒè¯ç”¨<mark>ï¼Œç»“è®ºç”¨<span class='important-red'>ã€‚åŸæ–‡ï¼š{m_raw}"
                        resp = client.chat.completions.create(model="deepseek-chat", messages=[{"role":"user","content":prompt}])
                        st.session_state['ai_output'] = re.sub(r'\*\*(.*?)\*\*', r'<mark>\1</mark>', resp.choices[0].message.content)
                else:
                    st.warning("è¯·è¡¥å…¨æ ‡é¢˜ã€å†…å®¹å’Œæ•™æ")

    with r_col:
        if 'ai_output' in st.session_state:
            st.markdown("âœï¸ **é¢„è§ˆä¸ç²¾ä¿®**")
            final_text = st.text_area("è§£æç»“æœ", value=st.session_state['ai_output'], height=450)
            if st.button("ğŸ’¾ ç¡®è®¤å½’æ¡£å…¥åº“", use_container_width=True):
                new_data = {"æ—¥æœŸ": datetime.now().strftime("%Y-%m-%d"), "æ ‡é¢˜": m_title, "æ¶‰åŠæ•™æ": " | ".join(m_books), "è€ƒç‚¹è®¾é—®": final_text, "ç´ æåŸæ–‡": m_raw}
                updated_df = pd.concat([df_cloud, pd.DataFrame([new_data])], ignore_index=True)
                
                repo = get_github_repo()
                csv_str = updated_df.to_csv(index=False, encoding='utf-8-sig')
                _, latest_sha = load_from_cloud(uid)
                if latest_sha:
                    repo.update_file(db_filename, "Save", csv_str, latest_sha)
                else:
                    repo.create_file(db_filename, "Init", csv_str)
                
                st.success("âœ… å·²åŒæ­¥è‡³äº‘ç«¯ï¼")
                del st.session_state['ai_output']
                st.rerun()

with tab2:
    if not df_cloud.empty:
        st.subheader("ğŸ“Š å¿«é€Ÿç´¢å¼•")
        st.dataframe(df_cloud[["æ—¥æœŸ", "æ ‡é¢˜", "æ¶‰åŠæ•™æ"]], use_container_width=True, hide_index=True)
        st.divider()
        search = st.text_input("ğŸ” æœç´¢åº“å†…ç´ æ...")
        show_df = df_cloud[df_cloud.apply(lambda r: r.astype(str).str.contains(search).any(), axis=1)] if search else df_cloud
        
        for i, row in show_df.iloc[::-1].iterrows():
            with st.expander(f"ğŸ“Œ {row['æ ‡é¢˜']} | {row['æ¶‰åŠæ•™æ']}"):
                c1, c2 = st.columns([1, 2.5])
                with c1:
                    st.markdown("**ğŸ“š æ¶‰åŠæ•™æ**")
                    for b in str(row['æ¶‰åŠæ•™æ']).split(" | "):
                        st.markdown(f"<span class='book-tag'>{b}</span>", unsafe_allow_html=True)
                with c2:
                    st.markdown("**ğŸ’¡ è”åŠ¨æ•™ç ”è§£æ**")
                    st.markdown(row['è€ƒç‚¹è®¾é—®'], unsafe_allow_html=True)
                st.divider()
                st.caption(f"ç´ æåŸæ–‡ï¼š{row['ç´ æåŸæ–‡']}")
                if st.button(f"ğŸ—‘ï¸ åˆ é™¤æ­¤è®°å½•", key=f"del_{i}"):
                    new_df = df_cloud.drop(i)
                    get_github_repo().update_file(db_filename, "Delete", new_df.to_csv(index=False, encoding='utf-8-sig'), current_sha)
                    st.rerun()
    else:
        st.info("åº“å†…å°šæ— ç´ æã€‚")
