import streamlit as st
import pandas as pd
from github import Github
from openai import OpenAI
import hashlib
import re
import io
import time
import uuid
from datetime import datetime

# --- 1. é¡µé¢é«˜çº§é…ç½® & è§†è§‰å‡€åŒ–è¡¥ä¸ ---
st.set_page_config(page_title="æ€æ”¿æ™ºåº“ - åå¸ˆå·¥ä½œå®¤", layout="wide", page_icon="ğŸ›ï¸")

st.markdown("""
    <style>
    /* æ ¸å¿ƒè¡¥ä¸ï¼šå¯¹æ™®é€šè®¿å®¢éšè—æ‰€æœ‰ç®¡ç†å…¥å£ */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    .stDeployButton {display:none;}
    #manage-app-button {display:none !important;}
    
    /* ç•Œé¢ç¾åŒ– */
    .stApp { background-color: #f8fafc; }
    mark { background-color: #ffff00 !important; color: #000 !important; padding: 0 3px; border-radius: 3px; font-weight: bold; }
    .important-red { color: #e11d48 !important; font-weight: bold; }
    .stExpander { border: 1px solid #e2e8f0 !important; border-radius: 12px !important; background: white !important; margin-bottom: 10px !important; }
    .book-tag { 
        background: #fee2e2; color: #b91c1c; padding: 2px 8px; border-radius: 4px; 
        font-size: 12px; font-weight: bold; display: block; margin-bottom: 5px; 
        text-align: center; border: 1px solid #fecaca;
    }
    </style>
    """, unsafe_allow_html=True)

# --- 2. æ ¸å¿ƒåç«¯å‡½æ•° ---
def get_github_repo():
    return Github(st.secrets["GH_TOKEN"]).get_repo(st.secrets["GH_REPO"])

def load_from_cloud(uid):
    file_path = f"material_lib_{uid}.csv"
    standard_cols = ["æ—¥æœŸ", "æ ‡é¢˜", "æ¶‰åŠæ•™æ", "è€ƒç‚¹è®¾é—®", "ç´ æåŸæ–‡"]
    try:
        repo = get_github_repo()
        content = repo.get_contents(file_path)
        fresh_url = f"{content.download_url}?v={uuid.uuid4()}"
        df = pd.read_csv(fresh_url)
        rename_map = {'ç´ ææ ‡é¢˜': 'æ ‡é¢˜', 'ç²¾ä¿®è§£æ': 'è€ƒç‚¹è®¾é—®', 'æ ¸å¿ƒè§£æ': 'è€ƒç‚¹è®¾é—®'}
        df.rename(columns=rename_map, inplace=True)
        for col in standard_cols:
            if col not in df.columns: df[col] = "æœªè®°å½•"
        return df[standard_cols], content.sha
    except:
        return pd.DataFrame(columns=standard_cols), None

# --- 3. ç™»å½•é€»è¾‘ (ä¸€äººä¸€åº“éš”ç¦») ---
if 'uid' not in st.session_state: st.session_state['uid'] = None
if 'display_df' not in st.session_state: st.session_state['display_df'] = None

if not st.session_state['uid']:
    st.markdown("<br><br>", unsafe_allow_html=True)
    col_l, col_m, col_r = st.columns([1, 2, 1])
    with col_m:
        st.title("ğŸ›ï¸ æ€æ”¿åå¸ˆæ™ºåº“")
        st.info("æ¬¢è¿ä½¿ç”¨åå¸ˆå·¥ä½œå®¤æ•™ç ”ç³»ç»Ÿã€‚è¯·è¾“å…¥æ‚¨çš„ DeepSeek API Key å¼€å¯ä¸ªäººåº“ã€‚")
        input_key = st.text_input("DeepSeek API Key", type="password")
        if st.button("ğŸš€ è¿›å…¥ç³»ç»Ÿ", use_container_width=True):
            if len(input_key) > 10:
                st.session_state['api_key'] = input_key
                st.session_state['uid'] = hashlib.md5(input_key.encode()).hexdigest()[:8]
                st.rerun()
            else:
                st.error("è¯·è¾“å…¥æœ‰æ•ˆçš„ API Key")
    st.stop()

# --- 4. æ•°æ®éš”ç¦»æ‰§è¡Œ ---
uid = st.session_state['uid']
db_filename = f"material_lib_{uid}.csv"

if st.session_state['display_df'] is None:
    df_cloud, _ = load_from_cloud(uid)
    st.session_state['display_df'] = df_cloud

# --- 5. ä¾§è¾¹æ  ---
with st.sidebar:
    st.header(f"ğŸ‘¤ è€å¸ˆæ‚¨å¥½")
    st.caption(f"æ‚¨çš„è¯†åˆ«ç : {uid}")
    st.divider()
    if st.button("ğŸ”„ åŒæ­¥äº‘ç«¯æ•°æ®", use_container_width=True):
        st.session_state['display_df'] = None
        st.rerun()
    st.divider()
    if not st.session_state['display_df'].empty:
        csv_io = io.BytesIO()
        st.session_state['display_df'].to_csv(csv_io, index=False, encoding='utf-8-sig')
        st.download_button("ğŸ“¥ å¯¼å‡ºæˆ‘çš„åº“", data=csv_io.getvalue(), file_name=f"åº“_{uid}.csv", use_container_width=True)
    if st.button("ğŸšª é€€å‡ºç™»å½•"):
        st.session_state.clear()
        st.rerun()

# --- 6. ä¸»åŠŸèƒ½å±•ç¤º ---
tab1, tab2 = st.tabs(["âœ¨ æ™ºèƒ½åŠ å·¥å½•å…¥", "ğŸ“‚ æˆ‘çš„ç»“æ„åŒ–çœ‹æ¿"])

with tab1:
    l_col, r_col = st.columns([1.2, 1])
    with l_col:
        with st.container(border=True):
            m_title = st.text_input("1. ç´ ææ ‡é¢˜")
            m_raw = st.text_area("2. ç´ æåŸæ–‡å†…å®¹", height=200)
            try:
                repo_obj = get_github_repo()
                pdf_list = sorted([f.name.replace('.pdf', '').replace('.PDF', '') for f in repo_obj.get_contents("data") if f.name.lower().endswith('.pdf')])
            except:
                pdf_list = ["å¿…ä¿®1", "å¿…ä¿®2", "å¿…ä¿®3", "å¿…ä¿®4"]
            m_books = st.multiselect("3. å…³è”æ•™æ", options=pdf_list)
            
            if st.button("ğŸ§  åå¸ˆ AI åˆ†æ", use_container_width=True):
                if m_title and m_books and m_raw:
                    client = OpenAI(api_key=st.session_state['api_key'], base_url="https://api.deepseek.com")
                    with st.spinner("æ­£åœ¨è¿›è¡Œå¤šç»´è”åŠ¨è§£æ..."):
                        prompt = f"é’ˆå¯¹ã€Š{m_title}ã€‹ç»“åˆæ•™æ {m_books} åˆ†æã€‚ä¸¥ç¦åŠ ç²—ã€‚æ ¸å¿ƒè¯ç”¨<mark>ï¼Œç»“è®ºç”¨<span class='important-red'>ã€‚åŸæ–‡ï¼š{m_raw}"
                        resp = client.chat.completions.create(model="deepseek-chat", messages=[{"role":"user","content":prompt}])
                        st.session_state['ai_output'] = re.sub(r'\*\*(.*?)\*\*', r'<mark>\1</mark>', resp.choices[0].message.content)
                else: st.warning("è¯·å®Œæ•´å¡«å†™ç´ æå†…å®¹")

    with r_col:
        if 'ai_output' in st.session_state:
            st.markdown("âœï¸ **é¢„è§ˆä¸ç²¾ä¿®**")
            final_text = st.text_area("è§£æç»“æœ", value=st.session_state['ai_output'], height=450)
            if st.button("ğŸ’¾ å½’æ¡£è‡³æˆ‘çš„åº“", use_container_width=True):
                new_row = {"æ—¥æœŸ": datetime.now().strftime("%Y-%m-%d"), "æ ‡é¢˜": m_title, "æ¶‰åŠæ•™æ": " | ".join(m_books), "è€ƒç‚¹è®¾é—®": final_text, "ç´ æåŸæ–‡": m_raw}
                st.session_state['display_df'] = pd.concat([st.session_state['display_df'], pd.DataFrame([new_row])], ignore_index=True)
                
                repo = get_github_repo()
                csv_str = st.session_state['display_df'].to_csv(index=False, encoding='utf-8-sig')
                _, latest_sha = load_from_cloud(uid)
                if latest_sha: repo.update_file(db_filename, "Update", csv_str, latest_sha)
                else: repo.create_file(db_filename, "Init", csv_str)
                
                st.success("âœ… å½’æ¡£æˆåŠŸï¼")
                del st.session_state['ai_output']
                st.rerun()

with tab2:
    df_show = st.session_state['display_df']
    if not df_show.empty:
        st.subheader("ğŸ“Š ç´ æç´¢å¼•æ¸…å•")
        st.dataframe(df_show[["æ—¥æœŸ", "æ ‡é¢˜", "æ¶‰åŠæ•™æ"]], use_container_width=True, hide_index=True)
        st.divider()
        search = st.text_input("ğŸ” æœç´¢å…³é”®è¯...")
        df_filtered = df_show[df_show.apply(lambda r: r.astype(str).str.contains(search).any(), axis=1)] if search else df_show
        
        for i, row in df_filtered.iloc[::-1].iterrows():
            with st.expander(f"ğŸ“Œ {row['æ ‡é¢˜']} | {row['æ¶‰åŠæ•™æ']}"):
                c1, c2 = st.columns([1, 2.5])
                with c1:
                    st.markdown("**ğŸ“š æ•™æ**")
                    for b in str(row['æ¶‰åŠæ•™æ']).split(" | "):
                        st.markdown(f"<span class='book-tag'>{b}</span>", unsafe_allow_html=True)
                with c2:
                    st.markdown("**ğŸ’¡ è”åŠ¨è§£æ**")
                    st.markdown(row['è€ƒç‚¹è®¾é—®'], unsafe_allow_html=True)
                if st.button(f"ğŸ—‘ï¸ åˆ é™¤", key=f"del_{i}"):
                    st.session_state['display_df'] = st.session_state['display_df'].drop(i)
                    csv_str = st.session_state['display_df'].to_csv(index=False, encoding='utf-8-sig')
                    _, latest_sha = load_from_cloud(uid)
                    get_github_repo().update_file(db_filename, "Delete", csv_str, latest_sha)
                    st.rerun()
    else:
        st.info("æ‚¨çš„ä¸ªäººåº“ç›®å‰ä¸ºç©ºã€‚")
