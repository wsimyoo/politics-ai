import streamlit as st
import pandas as pd
from openai import OpenAI
import os
from datetime import datetime
import hashlib

# 1. é¡µé¢é…ç½®
st.set_page_config(page_title="æ€æ”¿åå¸ˆæ™ºèƒ½ç´ æåº“", layout="wide", page_icon="ğŸ›ï¸")

# è‡ªå®šä¹‰æ ·å¼ï¼šå¼ºåŒ–è¡¨æ ¼è§‚æ„Ÿ
st.markdown("""
    <style>
    .stApp { background-color: #f8fafc; }
    .material-card { background: white; padding: 20px; border-radius: 12px; border-top: 5px solid #b91c1c; box-shadow: 0 4px 6px rgba(0,0,0,0.05); margin-bottom: 20px; }
    .stDataFrame { border-radius: 10px; border: 1px solid #e2e8f0; }
    </style>
    """, unsafe_allow_html=True)

def get_user_id(api_key):
    return hashlib.md5(api_key.encode()).hexdigest()[:8]

def get_available_books():
    data_path = "data"
    if not os.path.exists(data_path): return []
    files = [f for f in os.listdir(data_path) if f.lower().endswith('.pdf')]
    files.sort()
    return [f.replace('.pdf', '').replace('.PDF', '').replace('é«˜ä¸­æ”¿æ²»', '').strip() for f in files]

# 3. ç™»å½•é€»è¾‘
if 'api_key' not in st.session_state:
    st.session_state['api_key'] = None

if not st.session_state['api_key']:
    st.markdown("<br><br>", unsafe_allow_html=True)
    col_l, col_m, col_r = st.columns([1, 2, 1])
    with col_m:
        st.title("ğŸ›ï¸ æ€æ”¿åå¸ˆä¸“å±ç´ æç©ºé—´")
        input_key = st.text_input("DeepSeek API Key", type="password")
        if st.button("ğŸš€ è¿›å…¥æ•™ç ”å®¤", use_container_width=True):
            if len(input_key) > 10:
                st.session_state['api_key'] = input_key
                st.session_state['user_id'] = get_user_id(input_key)
                st.rerun()
else:
    user_id = st.session_state['user_id']
    user_db = f"material_lib_{user_id}.csv"
    book_options = get_available_books()
    
    with st.sidebar:
        st.header(f"ğŸ‘¤ è€å¸ˆ ID: {user_id}")
        if st.button("ğŸšª é€€å‡ºç™»å½•"):
            st.session_state['api_key'] = None
            st.rerun()
        st.divider()
        if os.path.exists(user_db):
            df_exp = pd.read_csv(user_db)
            csv = df_exp.to_csv(index=False).encode('utf-8-sig')
            st.download_button("ğŸ“¥ å¯¼å‡ºæ•™ç ”æ¸…å•", data=csv, file_name=f"ç´ æå¯¼å‡º_{datetime.now().strftime('%m%d')}.csv", use_container_width=True)

    tab1, tab2 = st.tabs(["âœ¨ ç´ ææ™ºèƒ½å½•å…¥", "ğŸ“‚ ç»“æ„åŒ–å…¨æ™¯çœ‹æ¿"])

    # --- TAB 1: å½•å…¥ ---
    with tab1:
        left_c, right_c = st.columns([1.2, 1])
        with left_c:
            with st.container(border=True):
                m_title = st.text_input("1. ç´ ææ ‡é¢˜")
                m_raw = st.text_area("2. ç´ æåŸæ–‡å†…å®¹", height=150)
                m_books = st.multiselect("3. å…³è”æ•™æï¼ˆåˆ†åˆ—ä¾æ®ï¼‰", options=book_options)
                
                if st.button("ğŸ§  AI è·¨æ•™ææ·±åº¦è§£æ", use_container_width=True):
                    client = OpenAI(api_key=st.session_state['api_key'], base_url="https://api.deepseek.com")
                    with st.spinner("æ•™ç ”åˆ†æä¸­..."):
                        prompt = f"ä½ æ˜¯æ”¿æ²»åå¸ˆã€‚è¯·åˆ†æç´ æã€Š{m_title}ã€‹åœ¨ã€Š{'ã€'.join(m_books)}ã€‹ä¸­çš„æ ¸å¿ƒè€ƒç‚¹ï¼Œå¹¶ç»™å‡ºæ•™å­¦è®¾é—®ã€‚å†…å®¹è¦ç²¾ç‚¼ã€‚\nåŸæ–‡ï¼š{m_raw}"
                        resp = client.chat.completions.create(model="deepseek-chat", messages=[{"role":"user","content":prompt}])
                        st.session_state['buffer'] = resp.choices[0].message.content

            if 'buffer' in st.session_state:
                st.markdown('<div class="editor-container" style="background:#fffbeb; padding:15px; border-radius:10px; border:1px solid #fcd34d;">', unsafe_allow_html=True)
                final_analysis = st.text_area("âœï¸ è€å¸ˆç²¾ä¿®åŒº", value=st.session_state['buffer'], height=300)
                if st.button("ğŸ’¾ å½’æ¡£ç´ æåº“", use_container_width=True):
                    new_entry = {"æ—¥æœŸ": datetime.now().strftime("%Y-%m-%d"), "æ ‡é¢˜": m_title, "æ¶‰åŠæ•™æ": " | ".join(m_books), "è€ƒç‚¹è®¾é—®": final_analysis, "åŸæ–‡å†…å®¹": m_raw}
                    df = pd.read_csv(user_db) if os.path.exists(user_db) else pd.DataFrame(columns=["æ—¥æœŸ","æ ‡é¢˜","æ¶‰åŠæ•™æ","è€ƒç‚¹è®¾é—®","åŸæ–‡å†…å®¹"])
                    df = pd.concat([df, pd.DataFrame([new_entry])], ignore_index=True)
                    df.to_csv(user_db, index=False, encoding='utf-8-sig')
                    st.success("å­˜æ¡£æˆåŠŸï¼")
                    del st.session_state['buffer']
                    st.rerun()
                st.markdown('</div>', unsafe_allow_html=True)

    # --- TAB 2: å®Œå–„åçš„ã€åˆ†åˆ—å‘ˆç°ã€‘æ¸…å•è¡¨ ---
    with tab2:
        if os.path.exists(user_db):
            df = pd.read_csv(user_db).fillna("")
            
            # ç»Ÿä¸€å­—æ®µåï¼ˆå…¼å®¹æ—§æ•°æ®ï¼‰
            mapping = {'å…³è”æ•™æ': 'æ¶‰åŠæ•™æ', 'æ ¸å¿ƒè€ƒç‚¹': 'è€ƒç‚¹è®¾é—®', 'æ ¸å¿ƒçŸ¥è¯†ç‚¹': 'è€ƒç‚¹è®¾é—®', 'ç²¾ä¿®è§£æ': 'è€ƒç‚¹è®¾é—®'}
            for old, new in mapping.items():
                if old in df.columns: df.rename(columns={old: new}, inplace=True)

            st.subheader("ğŸ“ ç»“æ„åŒ–æ•™ç ”ç´¢å¼•è¡¨")
            
            # æœç´¢ä¸è¿‡æ»¤
            col_search, col_filter = st.columns([2, 1])
            with col_search:
                q = st.text_input("ğŸ” å…¨å±€æ£€ç´¢å…³é”®è¯...")
            with col_filter:
                unique_books = sorted(list(set([b for sub in df['æ¶‰åŠæ•™æ'].str.split(" | ") for b in sub if b])))
                f_book = st.multiselect("ç­›é€‰ç‰¹å®šæ•™æ", options=unique_books)

            # æ•°æ®è¿‡æ»¤
            dff = df.copy()
            if q: dff = dff[dff.apply(lambda r: r.astype(str).str.contains(q).any(), axis=1)]
            if f_book: dff = dff[dff['æ¶‰åŠæ•™æ'].apply(lambda x: any(b in str(x) for b in f_book))]

            # --- æ ¸å¿ƒä¿®æ”¹ï¼šåˆ†åˆ—å‘ˆç°æ•°æ®æ„å»º ---
            view_df = dff.copy()
            # æ ¼å¼åŒ–è€ƒç‚¹åˆ—ï¼Œåªä¿ç•™å‰80å­—å¹¶å»æ‰æ¢è¡Œï¼Œæ–¹ä¾¿åˆ†åˆ—å¯¹æ¯”
            view_df['æ ¸å¿ƒè€ƒç‚¹æ¸…å•'] = view_df['è€ƒç‚¹è®¾é—®'].apply(lambda x: str(x).replace('\n', ' ')[:100] + '...')
            
            st.dataframe(
                view_df[["æ—¥æœŸ", "æ ‡é¢˜", "æ¶‰åŠæ•™æ", "æ ¸å¿ƒè€ƒç‚¹æ¸…å•"]],
                use_container_width=True,
                hide_index=True,
                column_config={
                    "æ—¥æœŸ": st.column_config.Column(width="small"),
                    "æ ‡é¢˜": st.column_config.Column("ç´ ææ ‡é¢˜", width="medium"),
                    "æ¶‰åŠæ•™æ": st.column_config.Column("å…³è”ä¹¦ç›® (åˆ†åˆ—)", width="medium"),
                    "æ ¸å¿ƒè€ƒç‚¹æ¸…å•": st.column_config.Column("è€ƒç‚¹ä¸æ•™å­¦è®¾é—® (åˆ†åˆ—æ±‡æ€»)", width="large"),
                }
            )

            st.divider()

            # ä¸‹æ–¹å±•ç¤ºè¯¦ç»†å†…å®¹
            st.subheader("ğŸ“‚ ç´ ææ¡£æ¡ˆè¯¦æƒ…")
            for i, row in dff.iloc[::-1].iterrows():
                with st.expander(f"ğŸ“Œ {row['æ¶‰åŠæ•™æ']} â€”â€” {row['æ ‡é¢˜']}"):
                    c1, c2 = st.columns([1.5, 1])
                    with c1:
                        st.markdown("**ã€è€ƒç‚¹æ·±åº¦è§£æã€‘**")
                        st.write(row['è€ƒç‚¹è®¾é—®'])
                    with c2:
                        st.markdown("**ã€åŸæ–‡å†…å®¹ã€‘**")
                        st.caption(row.get('åŸæ–‡å†…å®¹', "æ— åŸæ–‡"))
                    if st.button(f"ğŸ—‘ï¸ åˆ é™¤è¯¥è®°å½•", key=f"del_{i}"):
                        df.drop(i).to_csv(user_db, index=False, encoding='utf-8-sig')
                        st.rerun()
        else:
            st.info("æš‚æ— æ•°æ®ã€‚")

