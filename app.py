import streamlit as st
import pandas as pd
from openai import OpenAI
import os
from datetime import datetime
import hashlib
import re

# 1. é¡µé¢é«˜çº§é…ç½®
st.set_page_config(page_title="æ€æ”¿åå¸ˆæ™ºèƒ½ç´ æåº“", layout="wide", page_icon="ğŸ›ï¸")

# è‡ªå®šä¹‰ CSSï¼šæ¸²æŸ“è§å…‰ç¬”ã€çº¢å­—ã€æ•™ææ ‡ç­¾
st.markdown("""
    <style>
    .stApp { background-color: #f8fafc; }
    /* è§å…‰ç¬”é«˜äº®ï¼šå¼ºåˆ¶é»„è‰²èƒŒæ™¯ */
    mark { 
        background-color: #ffff00 !important; 
        color: #000 !important; 
        padding: 0 3px; 
        border-radius: 3px; 
        font-weight: bold;
    }
    /* é‡ç‚¹çº¢å­— */
    .important-red { color: #e11d48 !important; font-weight: bold; }
    /* å¡ç‰‡ç¾åŒ– */
    .stExpander { border: 1px solid #e2e8f0 !important; border-radius: 12px !important; background: white !important; margin-bottom: 10px !important; }
    /* æ•™æè‰²å—æ ‡ç­¾ */
    .book-tag { 
        background: #fee2e2; color: #b91c1c; padding: 2px 8px; border-radius: 4px; 
        font-size: 12px; font-weight: bold; display: block; margin-bottom: 5px; 
        text-align: center; border: 1px solid #fecaca;
    }
    </style>
    """, unsafe_allow_html=True)

# 2. æ ¸å¿ƒåç«¯å¼•æ“
def get_user_id(api_key):
    return hashlib.md5(api_key.encode()).hexdigest()[:8]

def get_available_books():
    d_path = "data"
    if not os.path.exists(d_path): os.makedirs(d_path)
    files = [f for f in os.listdir(d_path) if not f.startswith('.')]
    files.sort()
    return [f.replace('.pdf', '').replace('.PDF', '').replace('é«˜ä¸­æ”¿æ²»', '').strip() for f in files]

def auto_highlight_fix(text):
    """å°† AI å¯èƒ½ä¹ æƒ¯æ€§ä½¿ç”¨çš„ **åŠ ç²—** å¼ºåˆ¶è½¬ä¸º <mark> è§å…‰ç¬”æ ‡ç­¾"""
    return re.sub(r'\*\*(.*?)\*\*', r'<mark>\1</mark>', text)

def load_and_fix_db(file_path):
    """è‡ªåŠ¨ä¿®å¤æ—§æ•°æ®åˆ—åï¼Œå¹¶è¿”å›å¹²å‡€çš„æ•°æ®æ¡†"""
    standard_cols = ["æ—¥æœŸ", "æ ‡é¢˜", "æ¶‰åŠæ•™æ", "è€ƒç‚¹è®¾é—®", "ç´ æåŸæ–‡"]
    if not os.path.exists(file_path): 
        return pd.DataFrame(columns=standard_cols)
    try:
        df = pd.read_csv(file_path)
        rename_map = {
            'ç²¾ä¿®è§£æ': 'è€ƒç‚¹è®¾é—®', 'æ ¸å¿ƒçŸ¥è¯†ç‚¹': 'è€ƒç‚¹è®¾é—®', 
            'æ ¸å¿ƒè§£æ': 'è€ƒç‚¹è®¾é—®', 'åˆ†æç»“æœ': 'è€ƒç‚¹è®¾é—®',
            'å…³è”æ•™æ': 'æ¶‰åŠæ•™æ', 'æ¶‰åŠæ•™æ ': 'æ¶‰åŠæ•™æ',
            'åŸæ–‡': 'ç´ æåŸæ–‡', 'ç´ æåŸæ–‡å†…å®¹': 'ç´ æåŸæ–‡', 'åŸæ–‡å†…å®¹': 'ç´ æåŸæ–‡'
        }
        df.rename(columns=rename_map, inplace=True)
        # è¡¥é½ç¼ºå¤±åˆ—
        for col in standard_cols:
            if col not in df.columns: df[col] = "æœªè®°å½•"
        return df[standard_cols]
    except:
        return pd.DataFrame(columns=standard_cols)

# 3. ç™»å½•ä¸ä¾§è¾¹æ é€»è¾‘ï¼ˆåŒ…å«å¯¼å‡ºï¼‰
if 'api_key' not in st.session_state: st.session_state['api_key'] = None

if not st.session_state['api_key']:
    st.markdown("<br><br>", unsafe_allow_html=True)
    col_l, col_m, col_r = st.columns([1, 2, 1])
    with col_m:
        st.title("ğŸ›ï¸ æ€æ”¿åå¸ˆå·¥ä½œå®¤")
        input_key = st.text_input("è¯·è¾“å…¥ DeepSeek API Key å¼€å¯æ•™ç ”åº“", type="password")
        if st.button("ğŸš€ å¼€å¯å·¥ä½œå®¤", use_container_width=True):
            if len(input_key) > 10:
                st.session_state['api_key'] = input_key
                st.session_state['uid'] = get_user_id(input_key)
                st.rerun()
else:
    uid = st.session_state['uid']
    db_file = f"material_lib_{uid}.csv"
    book_options = get_available_books()

    # --- è¿™é‡Œæ˜¯æ ¸å¿ƒï¼šä¾§è¾¹æ ç®¡ç†ä¸ã€å¯¼å‡ºã€‘åŠŸèƒ½ ---
    with st.sidebar:
        st.header(f"ğŸ‘¤ è€å¸ˆ ID: {uid}")
        if st.button("ğŸšª é€€å‡ºç™»å½•", use_container_width=True):
            st.session_state['api_key'] = None
            st.rerun()
        
        st.divider()
        st.subheader("ğŸ“¥ æ•™ç ”å¯¼å‡ºä¸­å¿ƒ")
        # å®æ—¶åŠ è½½å½“å‰ç”¨æˆ·çš„æ•°æ®åº“
        df_for_export = load_and_fix_db(db_file)
        if not df_for_export.empty:
            # å¯¼å‡ºä¸º Excel å…¼å®¹çš„å¸¦ BOM çš„ CSV
            csv_data = df_for_export.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="ğŸ“¥ å¯¼å‡ºå…¨é‡æ¸…å• (CSV)",
                data=csv_data,
                file_name=f"æ€æ”¿æ•™ç ”ç´ æ_{datetime.now().strftime('%m%d')}.csv",
                mime='text/csv',
                use_container_width=True
            )
            st.success("æ•™ç ”æ¸…å•å·²å°±ç»ªï¼Œç‚¹å‡»ä¸Šæ–¹æŒ‰é’®ä¸‹è½½ã€‚")
        else:
            st.info("åº“å†…æš‚æ— ç´ æå¯ä¾›å¯¼å‡ºã€‚")
        
        st.divider()
        st.caption("æŠ€æœ¯æç¤ºï¼šè‹¥æ•™æåˆ—è¡¨æœªæ›´æ–°ï¼Œè¯·ä¸Šä¼  PDF åç‚¹å‡»å³ä¸Šè§’ä¸‰ç‚¹ -> Clear Cache å¼ºåˆ¶åˆ·æ–°ã€‚")

    # --- ä¸»åŠŸèƒ½åŒºï¼šTab åˆ‡æ¢ ---
    tab1, tab2 = st.tabs(["âœ¨ ç´ ææ™ºèƒ½åŠ å·¥å½•å…¥", "ğŸ“‚ ç»“æ„åŒ–å…¨æ™¯çœ‹æ¿"])

    # TAB 1: å½•å…¥ä¸è·¨æ•™ææ·±åº¦å…³è”
    with tab1:
        left_c, right_c = st.columns([1.2, 1])
        with left_c:
            with st.container(border=True):
                m_title = st.text_input("1. ç´ ææ ‡é¢˜", placeholder="è¾“å…¥ç´ æçš„æ ¸å¿ƒæ ‡é¢˜")
                m_raw = st.text_area("2. ç´ æåŸæ–‡å†…å®¹", height=150)
                m_books = st.multiselect("3. å…³è”å¤šæœ¬æ•™æï¼ˆå¼€å¯è·¨æ¨¡å—æ·±åº¦è”æƒ³ï¼‰", options=book_options)
                
                if st.button("ğŸ§  å¼€å¯è·¨æ•™ææ·±åº¦åˆ†æ", use_container_width=True):
                    if not m_title or not m_books:
                        st.warning("è¯·è¡¥å…¨æ ‡é¢˜å¹¶å‹¾é€‰æ•™æ")
                    else:
                        client = OpenAI(api_key=st.session_state['api_key'], base_url="https://api.deepseek.com")
                        with st.spinner("AI æ­£åœ¨è”åŠ¨è§£æå¹¶æ¶‚æŠ¹é‡ç‚¹é«˜äº®..."):
                            prompt = f"""ä½ æ˜¯ä¸€ä½é«˜ä¸­æ”¿æ²»ç‰¹çº§æ•™å¸ˆã€‚è¯·æ·±å…¥åˆ†æç´ æã€Š{m_title}ã€‹åœ¨ä»¥ä¸‹å¤šæœ¬æ•™æä¸­çš„äº¤å‰è€ƒç‚¹ï¼š{', '.join(m_books)}ã€‚
                            è¦æ±‚ï¼š
                            1. ã€è·¨æ•™æè”åŠ¨ã€‘ï¼šåˆ†æè¯¥ç´ æå¦‚ä½•å°†æ‰€é€‰çš„ä¸åŒæ•™ææ¨¡å—ï¼ˆå¦‚ç»æµã€å“²å­¦ã€æ³•æ²»ï¼‰æœ‰æœºç»“åˆã€‚
                            2. ã€æ ‡è®°è¯­æ³•ã€‘ï¼šä¸¥ç¦ä½¿ç”¨åŠ ç²—ã€‚æ ¸å¿ƒè€ƒç‚¹è¯å¿…é¡»åŒ…è£¹åœ¨ <mark> å’Œ </mark> ä¹‹é—´ï¼›æ ¸å¿ƒé‡‘å¥ç”¨ <span class='important-red'> å’Œ </span> åŒ…å›´ã€‚
                            3. ã€æ•™å­¦è®¾é—®ã€‘ï¼šé’ˆå¯¹å…³è”çŸ¥è¯†ç‚¹ç»™å‡ºé«˜è´¨é‡è®¾é—®ã€‚
                            åŸæ–‡ï¼š{m_raw}"""
                            resp = client.chat.completions.create(model="deepseek-chat", messages=[{"role":"user","content":prompt}])
                            # AI ç”Ÿæˆåç«‹å³æ‰§è¡Œâ€œåŠ ç²—è½¬è§å…‰ç¬”â€è‡ªåŠ¨ä¿®æ­£ï¼Œç¡®ä¿ 100% é«˜äº®
                            st.session_state['buffer'] = auto_highlight_fix(resp.choices[0].message.content)

            if 'buffer' in st.session_state:
                st.markdown("âœï¸ **é¢„è§ˆä¸ç²¾ä¿®**ï¼ˆæ”¯æŒæ‰‹åŠ¨ç¼–è¾‘æ ‡ç­¾ï¼‰")
                final_res = st.text_area("è€ƒç‚¹è§£æè¯¦æƒ…", value=st.session_state['buffer'], height=300)
                if st.button("ğŸ’¾ ç¡®è®¤å­˜å…¥äº‘ç«¯åº“", use_container_width=True):
                    df_current = load_and_fix_db(db_file)
                    new_row = {"æ—¥æœŸ": datetime.now().strftime("%Y-%m-%d"), "æ ‡é¢˜": m_title, "æ¶‰åŠæ•™æ": " | ".join(m_books), "è€ƒç‚¹è®¾é—®": final_res, "ç´ æåŸæ–‡": m_raw}
                    pd.concat([df_current, pd.DataFrame([new_row])], ignore_index=True).to_csv(db_file, index=False, encoding='utf-8-sig')
                    st.success("âœ… å½’æ¡£æˆåŠŸï¼å·²åŒæ­¥è‡³ä¾§è¾¹æ å¯¼å‡ºåŠå…¨æ™¯çœ‹æ¿ã€‚")
                    del st.session_state['buffer']
                    st.rerun()

    # TAB 2: ç»“æ„åŒ–çœ‹æ¿
    with tab2:
        df_display = load_and_fix_db(db_file)
        if not df_display.empty:
            st.subheader("ğŸ“ å¿«é€Ÿç´¢å¼•æ¸…å•")
            st.dataframe(df_display[["æ—¥æœŸ", "æ ‡é¢˜", "æ¶‰åŠæ•™æ"]], use_container_width=True, hide_index=True)
            
            st.divider()
            st.subheader("ğŸ“– ç»“æ„åŒ–çœ‹æ¿ (é«˜äº®åˆ†åˆ—è§†å›¾)")
            
            search_key = st.text_input("ğŸ” æœç´¢å…¨åº“ç´ æå…³é”®è¯...")
            show_df = df_display[df_display.apply(lambda r: r.astype(str).str.contains(search_key).any(), axis=1)] if search_key else df_display
            
            for i, row in show_df.iloc[::-1].iterrows():
                with st.expander(f"ğŸ“Œ {row['æ¶‰åŠæ•™æ']} | {row['æ ‡é¢˜']}"):
                    col_l, col_r = st.columns([1, 2.5])
                    with col_l:
                        st.markdown("**ğŸ“š æ¶‰åŠæ•™æ**")
                        for b in str(row['æ¶‰åŠæ•™æ']).split(" | "):
                            st.markdown(f"<span class='book-tag'>{b}</span>", unsafe_allow_html=True)
                    with col_r:
                        st.markdown("**ğŸ’¡ æ·±åº¦è§£æ (å«è§å…‰ç¬”é‡ç‚¹)**")
                        # æœ€ç»ˆæ¸²æŸ“ HTML é«˜äº®æ•ˆæœ
                        st.markdown(row['è€ƒç‚¹è®¾é—®'], unsafe_allow_html=True)
                    
                    st.divider()
                    st.caption(f"ç´ æåŸæ–‡å‚è€ƒï¼š{row.get('ç´ æåŸæ–‡', '')}")
                    if st.button(f"ğŸ—‘ï¸ åˆ é™¤è¯¥è®°å½•", key=f"del_{i}"):
                        df_display.drop(i).to_csv(db_file, index=False, encoding='utf-8-sig')
                        st.rerun()
        else:
            st.info("åº“å†…å°šæ— æ•™ç ”ç´ æã€‚")

